{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Colm Mooney - 20325583\n",
        "\n",
        "Goal: Understand how different audio features used with Hidden Markov Models affects Speech Recognition task."
      ],
      "metadata": {
        "id": "1-O8gBgzdwVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AgjqFiJR279",
        "outputId": "e3443c77-6b28-49f3-f809-59e10d632c4b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q keras"
      ],
      "metadata": {
        "id": "TSiRAGIhVQhy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hmmlearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuMy1GqJnNQn",
        "outputId": "cb886098-e6ee-4801-c3ae-483ec5dd662d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hmmlearn\n",
            "  Downloading hmmlearn-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.1/161.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn!=0.22.0,>=0.16 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.2.2)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (3.5.0)\n",
            "Installing collected packages: hmmlearn\n",
            "Successfully installed hmmlearn-0.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras"
      ],
      "metadata": {
        "id": "zb3evPc3VZHg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Code works, just isn't needed currently after doing it once (Splits code in dataset to 80:20, 80% for training, 20% for testing.)\n",
        "#import os\n",
        "#import shutil\n",
        "\n",
        "# Define paths for train and test directories\n",
        "#data_directory = '/content/drive/MyDrive/dataset'\n",
        "#train_directory = os.path.join(data_directory, 'train_data')\n",
        "#test_directory = os.path.join(data_directory, 'test_data')\n",
        "\n",
        "#os.makedirs(train_directory, exist_ok=True)\n",
        "#os.makedirs(test_directory, exist_ok=True)\n",
        "\n",
        "#wav_files = glob.glob(data_directory + '/*.wav')\n",
        "#train_files, test_files = train_test_split(wav_files, test_size=0.2, random_state=42) #80:20 split\n",
        "\n",
        "# Move files to Train directory\n",
        "#for file_path in train_files:\n",
        "#    file_name = os.path.basename(file_path)\n",
        "#    shutil.move(file_path, os.path.join(train_directory, file_name))\n",
        "\n",
        "# Move files to Test directory\n",
        "#for file_path in test_files:\n",
        "#    file_name = os.path.basename(file_path)\n",
        "#    shutil.move(file_path, os.path.join(test_directory, file_name))\n"
      ],
      "metadata": {
        "id": "TNVS5auSSbx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import glob\n",
        "\n",
        "data_directory = '/content/drive/MyDrive/dataset'"
      ],
      "metadata": {
        "id": "TeyDDcobo-oA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "from hmmlearn import hmm"
      ],
      "metadata": {
        "id": "82c42mv_p2qL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the Cepstrum manually\n",
        "#Cepstrum: Derive the cepstrum of the audio files. (you need to code it manually)\n",
        "def compute_cepstrum_manual(y, sr, n_fft=512):\n",
        "    # Step 1: Compute Power Spectrum\n",
        "    stft_mag = np.abs(librosa.stft(y, n_fft=n_fft))\n",
        "    power_spectrum = stft_mag**2\n",
        "\n",
        "    # Step 2: Take Logarithm\n",
        "    log_power_spectrum = np.log(power_spectrum)\n",
        "\n",
        "    # Step 3: Inverse Fourier Transform (IFFT)\n",
        "    cepstrum = np.fft.irfft(log_power_spectrum, axis=0)\n",
        "\n",
        "    # Step 4: Extract Cepstral Coefficients (e.g., first 13 coefficients)\n",
        "    cepstral_coeffs = cepstrum[:13, :].T  # Transpose and select desired coefficients\n",
        "\n",
        "    return cepstral_coeffs\n"
      ],
      "metadata": {
        "id": "MOAsPKjuatYv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "efOzSWyGdrNC"
      },
      "outputs": [],
      "source": [
        "#Given Code from Assignment\n",
        "\n",
        "\n",
        "#/content/drive/MyDrive/dataset\n",
        "#data_directory = '/content/drive/MyDrive/dataset'\n",
        "#loaded_data = load_data(data_directory)\n",
        "def compute_cepstrum_manual(y, sr, n_fft=512):\n",
        "    stft_mag = np.abs(librosa.stft(y, n_fft=n_fft))\n",
        "    power_spectrum = stft_mag**2\n",
        "    log_power_spectrum = np.log(power_spectrum)\n",
        "    cepstrum = np.fft.irfft(log_power_spectrum, axis=0)\n",
        "    cepstral_coeffs = cepstrum[:13, :].T  # Select first 13 coefficients\n",
        "    return cepstral_coeffs\n",
        "\n",
        "\n",
        "\n",
        "def load_data(directory):\n",
        "    data = {}\n",
        "    for file in os.listdir(directory):\n",
        "        if file.endswith(\".wav\"):\n",
        "            digit = file.split('_')[0]\n",
        "            y, sr = librosa.load(os.path.join(directory, file), sr=None)\n",
        "\n",
        "\n",
        "            # Compute features (Make Spectogram, Mel Spectogram, Cepstrum and MFCC)\n",
        "            # example:\n",
        "            spectrogram = np.abs(librosa.stft(y, n_fft=512)) #2-1\n",
        "            mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=512) #2-2\n",
        "            cepstrum = compute_cepstrum_manual(y, sr)  # 2-3\n",
        "            mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20, center=False, n_fft = 512, hop_length = 15, win_length = 30) #2-4  #2-4\n",
        "\n",
        "            if digit not in data:\n",
        "                data[digit] = []\n",
        "            data[digit].append(mfccs.T)  # Transposed to make it (time, feature). Replace mfccs with your feature and reshape accordingly\n",
        "    return data\n",
        "\n",
        "\n",
        "\n",
        "def load_test_data(directory):\n",
        "    test_data = []\n",
        "    labels = []\n",
        "    for file in os.listdir(directory):\n",
        "        if file.endswith(\".wav\"):\n",
        "            digit = file.split('_')[0]\n",
        "            y, sr = librosa.load(os.path.join(directory, file), sr=None)\n",
        "\n",
        "            # COMPUTE FEATURES FOR TEST DATA HERE\n",
        "            spectrogram = np.abs(librosa.stft(y, n_fft=512)) #2-1\n",
        "            mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=512) #2-2\n",
        "            cepstrum = compute_cepstrum_manual(y, sr)  # 2-3\n",
        "            mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20, center=False, n_fft = 512, hop_length = 15, win_length = 30) #2-4\n",
        "\n",
        "\n",
        "\n",
        "            test_data.append(mfccs.T) # Transposed to make it (time, feature). Replace mfccs with your feature and reshape accordingly\n",
        "            labels.append(digit)\n",
        "    return test_data, labels\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_hmms(data, n_components=5, covariance_type='diag'):\n",
        "    models = {}\n",
        "    for digit, features in data.items():\n",
        "        model = hmm.GaussianHMM(n_components=2, n_iter=10, covariance_type='diag', params='mct', init_params='mc')\n",
        "        features = np.concatenate(features)\n",
        "        model.fit(features)\n",
        "        models[digit] = model\n",
        "    return models\n",
        "\n",
        "\n",
        "def test_model(models, test_data, labels):\n",
        "    correct_predictions = 0\n",
        "    total_predictions = len(labels)\n",
        "\n",
        "    for features, label in zip(test_data, labels):\n",
        "        best_score, best_digit = float('-inf'), None\n",
        "        for digit, model in models.items():\n",
        "            score = model.score(features)\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_digit = digit\n",
        "        if best_digit == label:\n",
        "            correct_predictions += 1\n",
        "\n",
        "    print(f\"Total predictions: {total_predictions}\")\n",
        "    print(f\"Correct predictions: {correct_predictions}\")\n",
        "    accuracy = correct_predictions / total_predictions\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "\n",
        "# Load train data\n",
        "train_data = load_data('/content/drive/MyDrive/dataset/train_data')\n",
        "models = train_hmms(train_data)  # Pass the train_data variable\n",
        "\n",
        "# Load test data\n",
        "test_data, test_labels = load_test_data('/content/drive/MyDrive/dataset/test_data')  # Pass the test_files variable\n",
        "\n",
        "accuracy = test_model(models, test_data, test_labels)\n",
        "print(f\"Model accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HL3W5Z1k9pIa",
        "outputId": "ade140af-631a-460a-fe2f-ba8197135f1e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total predictions: 600\n",
            "Correct predictions: 486\n",
            "Model accuracy: 0.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ordered by Accuracy:\n",
        "\n",
        "Total predictions: 600\n",
        "\n",
        "Test 8:\n",
        "Correct predictions: 190\n",
        "Model accuracy: 0.32\n",
        "mfccs = 2\n",
        "\n",
        "Test 4:\n",
        "Correct predictions: 368\n",
        "Model accuracy: 0.61\n",
        "mfccs = 5\n",
        "\n",
        "Test 10:\n",
        "Correct predictions: 374\n",
        "Model accuracy: 0.62\n",
        "mfccs = 250\n",
        "\n",
        "Test 11:\n",
        "Correct predictions: 375\n",
        "Model accuracy: 0.62\n",
        "mfccs = 100\n",
        "\n",
        "Test 9:\n",
        "Correct predictions: 379\n",
        "Model accuracy: 0.63\n",
        "mfccs = 200\n",
        "\n",
        "Test 2:\n",
        "Correct predictions: 385\n",
        "Model accuracy: 0.64\n",
        "mfccs =50\n",
        "\n",
        "Test 12:\n",
        "Correct predictions: 438\n",
        "Model accuracy: 0.73\n",
        "mfccs = 30\n",
        "\n",
        "Test 3:\n",
        "Correct predictions: 453\n",
        "Model accuracy: 0.76\n",
        "mfccs = 10\n",
        "\n",
        "Test 5:\n",
        "Correct predictions: 464\n",
        "Model accuracy: 0.77\n",
        "mfccs = 15\n",
        "\n",
        "Test 13:\n",
        "Correct predictions: 461\n",
        "Model accuracy: 0.77\n",
        "mfccs = 21\n",
        "\n",
        "Test 4:\n",
        "Correct predictions: 473\n",
        "Model accuracy: 0.79\n",
        "mfccs = 25\n",
        "\n",
        "Test 7:\n",
        "Correct predictions: 475\n",
        "Model accuracy: 0.79\n",
        "mfccs = 19\n",
        "\n",
        "Test 1:\n",
        "Correct predictions: 484\n",
        "Model accuracy: 0.81\n",
        "mfccs = 20\n",
        "(hop_length = 256) = .79\n",
        "\n",
        "Test 6:\n",
        "Correct predictions: 495\n",
        "Model accuracy: 0.82\n",
        "mfccs = 18\n",
        "\n"
      ],
      "metadata": {
        "id": "VlgIu3geSK9G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The amount of correct predictions is dependent on MFCCs. The accuracy of the model varies due to how close the mfccs is close to 20. Test 1 has achieved the highest accuracy of the observed, getting 81%, and the lowest amount of accuracy is 32% with MCC being 2. If changed the MCC to 1, the accuracy would have been even lower.\n",
        "\n",
        "The Accuracy for the model continues to drop the higher the mfcc gets. When the mfccs is 50, 200, 100, or 250 it shows that there isn't a point in going any higher than 50. The accuracy drops completely. It's being overfitted, and when the mfcc was 2, it was being underfitted.\n",
        "\n",
        "Changing the FFT window did not seem to affect the accuracy. The values used were 128, 256, 512, 1024\n",
        "\n",
        "For the best results, I believe consistently retraining the model when mfcc is between 18-22 would lead to the best result, with 20 most likely being the highest. This range offers a good compromise between complexity & accuracy.\n",
        "\n",
        "I tested changing the fmin, where I changed it from 0 to 10. Doing so made the program less accurate on when mfcc = 20. I got a result of .76. Changing fmin to 20 made it even less accurate, going to .73\n",
        "\n",
        "Setting fmin to 0, and fmax = 100, The accuracy dramatically got worse. Going to 0.23 accuracy. Setting fmax = 500 only increased it marginally to 0.36. This discouraged me from changing fmin & fmax at all as it only made the model less accurate.\n",
        "\n",
        "Hop length affects the time resolution but has no noticeable effects when tested in this code. That isn't until it is paired with win_length. I did some tests where the hop length was half of win_length so there was good overlap between frames. And after training the data, there were no noticeable changes when the window & hop length were decently large. However, there was a significant increase in accuracy when the window length & hop length were short. With a window length of 30 & a hop length of 15, the accuracy got slightly better, going up 2-4%. This also made the time it took for the code to process, however, take around 2 minutes per try. This low win_length is useful when trying to recognize speech.\n",
        "\n",
        "The center being true or false was tested, but it had no noticeable impact on the accuracy. Whether it was on or off, the level of accuracy was the same."
      ],
      "metadata": {
        "id": "_Q4FD5bm1EQq"
      }
    }
  ]
}